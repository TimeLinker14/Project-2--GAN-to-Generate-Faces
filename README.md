# Project-2--GAN-to-Generate-Faces
Implementation using PyTorch


Introduction

Generative Adversarial Networks (GAN’s) are an approach to generative modeling using  deep learning methods, such as convolutional neural networks. These are comprised of node layers, containing an input layer, one or more hidden layers, and an output layer. Each node connects to another and has an associated weight and threshold. If the output of any individual node is above the specified threshold value, that node is activated, sending data to the next layer of the network.

In this project, the purpose was to implement a model and train it with data from the known ‘celebA’ dataset, which contains around 200,000 images of celebrities. The point is to get an output which is comprised of fake faces generated by the model. In this case, I used a pre-processed version of the ‘celebA’ dataset simply for computational purposes. This pre-processed version contains around 40,000 images, which are the inputs that the model was trained in. 

The model is based on the “discriminator vs generator” conundrum. The job of the discriminator is to look at an image and output whether or not it is a real training image or a fake image from the generator. During training, the generator is constantly trying to outsmart the discriminator by generating better and better fakes, while the discriminator is working to become a better detective and correctly classify the real and fake images. The equilibrium of this game is when the generator is generating perfect fakes that look as if they came directly from the training data, and the discriminator is left to always guess at 50% confidence that the generator output is real or fake.

The discriminator is made up of strided convolution layers, batch norm layers, and LeakyReLU activations. The input is a 3x64x64 input image and the output is a scalar probability that the input is from the real data distribution. The generator is comprised of convolutional-transpose layers, batch norm layers, and ReLU activations. The input is a latent vector , that is drawn from a standard normal distribution and the output is a 3x64x64 RGB image.

Explanation

First, importing the correct libraries is important, I used the ones shown in Figure 2.  As a side note, I also set a manual seed so that the resulting output will stay the same, although this is optional and can be removed.
Then, several variables were instantiated. These include things such as the amount of epochs, the learning rate, the amount of GPU’s used (I used 4. If none then the program will just use the CPU), etc. Also, the directory where the training data can be found is declared here as well. 
Next, the dataset is imported and a data loader is created and a few images are displayed, as shown in Figure 3.

In several papers about GAN’s, it is mentioned that all model weights have to be randomly initialized from a Normal distribution with parameters  and . In Figure 4, the weights_init(m) function can be seen, which takes an initialized model as input and reinitializes all convolutional, convolutional-transpose, and batch normalization layers. Next, two classes are created: the Generator class and the Discriminator class. After this, a generator is instantiated and the weights_init(m) function is applied to it.
Now, the Discriminator is a binary classification network that takes an input, in this case images, and it outputs a number that represents a probability that the input image is fake or real. After a series several layers, the Discriminator outputs this probability through a Sigmoid activation function. Again, we use the weights_init(m) and apply it.
Then, after the Discriminator and the Generator are created, we can define how they learn through some functions, such as the so called Loss function and with optimizers. Several similar projects, when using PyTorch, use a Binary Cross Entropy loss function. After that, the labels are defined ( for real images and  for fake images) and two optimizers are created (both are Adam optimizers with learning rate  and . Finally, we train our model and look at the resulting output. 

Results & Conclusion

In this case, only one epoch was used. This is just because when using several epochs, the kernel on my virtual environment died and did not finish the training. One epoch may not be a lot, but the results were satisfactory. 
In Figure 7 we can see a plot of the Discriminator and Generator losses versus training iterations and in Figure 8 we can see the final result. The faces are a bit weird, but it is possible to make out a human resemblance.
I am convinced that if I were to run more epochs of this program, the result could be better, however, given the time constraints (hours and hours of training) I feel the final output is adequate. It is true that the output presented is not the optimal one, nor even a “good” one maybe. It would be good to experiment with several different parameters, such as the learning rate, to see how the output would react.

In conclusion, this project was a great learning experience. I had to delve a little bit into some research papers and a lot of obscure webpages and GitHub posts with already-completed projects to gain better understanding of how a GAN works.  One thing I can say is that understanding the mathematical framework in which GAN’s operate is essential to the full realization of this project. A lot of times I got stuck because I just did not understand in depth how the model was supposed to work. Also, the pre-process of the input data was one of the most difficult and important parts about this project.
